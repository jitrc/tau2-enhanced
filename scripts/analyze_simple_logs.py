#!/usr/bin/env python3
"""
Analysis script for simplified execution logs from tau2-enhanced.

This script uses the new LogAnalyzer and LogVisualizer to process the
execution logs generated by the LoggingEnvironment and produces both
a console report and interactive HTML visualizations.
"""

import argparse
import json
from pathlib import Path
import sys

# Add the parent directory to the path to allow imports from tau2_enhanced
sys.path.append(str(Path(__file__).resolve().parents[1]))

from tau2_enhanced.analysis.analyzer import LogAnalyzer
from tau2_enhanced.analysis.visualizer import LogVisualizer
from tau2_enhanced.logging.events import ToolExecutionEvent


def convert_state_snapshots_to_events(state_snapshots):
    """
    Convert state snapshots to ToolExecutionEvent objects for analysis.

    Args:
        state_snapshots: List of state snapshot objects

    Returns:
        List of ToolExecutionEvent objects that can be analyzed by LogAnalyzer
    """
    events = []

    # Group snapshots by pairs (before/after tool calls)
    for i, snapshot in enumerate(state_snapshots):
        metadata = snapshot.get('metadata', {})
        tool_name = metadata.get('tool_name', 'unknown_tool')

        # Create a ToolExecutionEvent from state snapshot
        if 'before_' in snapshot.get('action_trigger', ''):
            # This is a before snapshot, create a mock ToolExecutionEvent
            event = ToolExecutionEvent(
                timestamp=snapshot.get('timestamp', 0),
                tool_name=tool_name,
                success=True,  # Assume success since we have state changes
                execution_time=0.1,  # Mock execution time
                requestor=metadata.get('requestor', 'assistant'),
                state_changed=True,  # State snapshots imply state change
                result_size=100,  # Mock result size
                args_count=metadata.get('args_count', 0),
                tool_call_id=f"{tool_name}_{i}",
                args_complexity_score=0.3,  # Mock complexity
                result_complexity_score=0.4,
                result_contains_errors=False,
                validation_errors=[]
            )
            events.append(event)

    print(f"   Converted {len(events)} state snapshots to ToolExecutionEvent objects.")
    return events


def analyze_logs(log_file: Path, output_dir: Path):
    """
    Loads, analyzes, and visualizes execution logs from a file.
    """
    print(f"ğŸ“ Loading logs from: {log_file}")
    
    # Determine which file is which and load both
    if '_enhanced_logs' in log_file.name:
        enhanced_log_file = log_file
        task_log_file = Path(str(log_file).replace('_enhanced_logs', ''))
    else:
        task_log_file = log_file
        enhanced_log_file = Path(str(log_file).replace('.json', '_enhanced_logs.json'))

    try:
        with enhanced_log_file.open('r') as f:
            tool_data = json.load(f)
        print(f"  |-> Loaded tool logs from: {enhanced_log_file}")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âŒ Error loading tool log file: {e}")
        tool_data = {}

    try:
        with task_log_file.open('r') as f:
            task_data = json.load(f)
        print(f"  |-> Loaded task logs from: {task_log_file}")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âŒ Error loading task log file: {e}")
        task_data = {}

    # Custom merging logic
    merged_data = task_data.copy()
    if tool_data and 'simulations' in tool_data and 'simulations' in merged_data:
        if isinstance(tool_data['simulations'], dict) and isinstance(merged_data['simulations'], list):
            task_sims_by_id = {sim['id']: sim for sim in merged_data['simulations'] if 'id' in sim}
            for sim_id, tool_sim_data in tool_data['simulations'].items():
                if sim_id in task_sims_by_id:
                    task_sims_by_id[sim_id].update(tool_sim_data)
            merged_data['simulations'] = list(task_sims_by_id.values())

    # The LogAnalyzer is capable of handling different log formats.
    # We pass the entire loaded JSON data to it.
    analyzer = LogAnalyzer(merged_data)

    # Check if any tool events were found
    if analyzer.df.empty:
        print("ğŸ¤· No tool execution events found in the file.")
        return

    print(f"ğŸ”¬ Found {len(analyzer.df)} tool execution events to analyze.")
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. Analyze the logs
    print("\n" + "="*50)
    print("ğŸ“Š SUMMARY METRICS")
    print("="*50)
    summary = analyzer.get_summary_metrics()
    for key, value in summary.items():
        if isinstance(value, float):
            print(f"  - {key.replace('_', ' ').title()}: {value:.3f}")
        else:
            print(f"  - {key.replace('_', ' ').title()}: {value}")

    print("\n" + "="*50)
    print("ğŸ› ï¸ TOOL PERFORMANCE")
    print("="*50)
    tool_perf = analyzer.get_tool_performance()
    print(tool_perf.to_string(index=False))

    print("\n" + "="*50)
    print("ğŸ”¥ FAILURE ANALYSIS")
    print("="*50)
    failures = analyzer.get_failure_analysis()
    if not failures.empty:
        print(failures.to_string(index=False))
    else:
        print("  ğŸ‰ No failures recorded.")

    print("\n" + "="*50)
    print("ğŸ”„ STATE CHANGE ANALYSIS")
    print("="*50)
    state_analysis = analyzer.get_state_change_analysis()
    if not state_analysis.empty:
        print(state_analysis.to_string(index=False))
    else:
        print("  ğŸ¤· No state change data available to analyze.")

    print("\n" + "="*50)
    print("ğŸ”— TOOL SEQUENCE ANALYSIS")
    print("="*50)
    sequence_analysis = analyzer.get_tool_sequence_analysis()
    if not sequence_analysis.empty:
        print("  Top 10 most common tool transitions:")
        print(sequence_analysis.head(10).to_string(index=False))
    else:
        print("  ğŸ¤· Not enough data to analyze tool sequences.")

    # 2. Visualize the results
    print("\n" + "="*50)
    print("ğŸ“ˆ GENERATING VISUALIZATIONS")
    print("="*50)
    visualizer = LogVisualizer(analyzer)

    try:
        # Summary Dashboard
        summary_fig = visualizer.create_summary_dashboard()
        summary_path = output_dir / "summary_dashboard.html"
        summary_fig.write_html(summary_path)
        print(f"  âœ… Summary dashboard saved to: {summary_path}")

        # Failure Analysis Plot
        failure_fig = visualizer.create_failure_analysis_plot()
        failure_path = output_dir / "failure_analysis.html"
        failure_fig.write_html(failure_path)
        print(f"  âœ… Failure analysis plot saved to: {failure_path}")

        # State Change Plot
        state_change_fig = visualizer.create_state_change_plot()
        state_change_path = output_dir / "state_change_analysis.html"
        state_change_fig.write_html(state_change_path)
        print(f"  âœ… State change analysis plot saved to: {state_change_path}")

        # Tool Flow Sankey
        sankey_fig = visualizer.create_tool_flow_sankey()
        sankey_path = output_dir / "tool_flow_sankey.html"
        sankey_fig.write_html(sankey_path)
        print(f"  âœ… Tool flow Sankey diagram saved to: {sankey_path}")

        # Bottleneck Plot
        bottleneck_fig = visualizer.create_performance_bottleneck_plot()
        bottleneck_path = output_dir / "performance_bottlenecks.html"
        bottleneck_fig.write_html(bottleneck_path)
        print(f"  âœ… Performance bottleneck plot saved to: {bottleneck_path}")

        # Comprehensive Tool Report
        tool_report_path = output_dir / "tool_report.html"
        visualizer.create_tool_report(str(tool_report_path), log_file.name)
        print(f"  âœ… Comprehensive tool report saved to: {tool_report_path}")

        # Comprehensive Simulation Report
        report_path = output_dir / "report.html"
        visualizer.create_comprehensive_report(str(report_path), log_file.name)
        print(f"  âœ… Comprehensive simulation report saved to: {report_path}")

    except Exception as e:
        print(f"  âŒ Error during visualization: {e}")

    print("\nğŸ‰ Analysis complete!")
    print(f"\nğŸ“„ For a comprehensive overview, open: {output_dir / 'report.html'}")
    print(f"ğŸ› ï¸ For a detailed tool analysis, open: {output_dir / 'tool_report.html'}")


def main():
    parser = argparse.ArgumentParser(
        description="Analyze simplified execution logs from tau2-enhanced."
    )
    parser.add_argument(
        "log_file",
        type=Path,
        help="Path to the JSON results file containing execution_logs."
    )
    parser.add_argument(
        "-o", "--output",
        type=Path,
        default=Path("analysis_results"),
        help="Base directory to save analysis plots."
    )
    args = parser.parse_args()

    # Create a subfolder in the output directory named after the input file
    output_subdir = args.output / args.log_file.stem
    print(f"ğŸ’¾ Output will be saved to: {output_subdir}")

    analyze_logs(args.log_file, output_subdir)


if __name__ == "__main__":
    main()
