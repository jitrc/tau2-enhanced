#!/usr/bin/env python3
"""
Analysis script for simplified execution logs from tau2-enhanced.

This script uses the new LogAnalyzer and LogVisualizer to process the
execution logs generated by the LoggingEnvironment and produces both
a console report and interactive HTML visualizations.
"""

import argparse
import json
from pathlib import Path
import sys

# Add the parent directory to the path to allow imports from tau2_enhanced
sys.path.append(str(Path(__file__).resolve().parents[1]))

from tau2_enhanced.analysis.analyzer import LogAnalyzer
from tau2_enhanced.analysis.visualizer import LogVisualizer


def analyze_logs(log_file: Path, output_dir: Path):
    """
    Loads, analyzes, and visualizes execution logs from a file.

    Args:
        log_file: Path to the JSON file containing the execution logs.
        output_dir: Directory to save the analysis reports and plots.
    """
    print(f"üìÅ Loading logs from: {log_file}")
    try:
        with log_file.open('r') as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"‚ùå Error loading log file: {e}")
        return

    # The `simulations` key can be a list or a dictionary. We need to handle both.
    try:
        simulations_data = data.get('simulations', [])
        if isinstance(simulations_data, list) and simulations_data:
            first_simulation = simulations_data[0]
        elif isinstance(simulations_data, dict) and simulations_data:
            first_simulation = next(iter(simulations_data.values()))
        else:
            print("‚ùå 'simulations' field is empty or has an unexpected type.")
            return

        # The location of execution_logs can vary.
        # Try finding it inside `enhanced_logs` first, then fall back to the top level.
        if 'enhanced_logs' in first_simulation and 'execution_logs' in first_simulation['enhanced_logs']:
            log_data = first_simulation['enhanced_logs']['execution_logs']
        elif 'execution_logs' in first_simulation:
            log_data = first_simulation['execution_logs']
        else:
            print("‚ùå Could not find 'execution_logs' in the first simulation.")
            print("   Please ensure you are using a results file with enhanced logging enabled.")
            return

    except (KeyError, IndexError, TypeError, StopIteration):
        print("‚ùå Could not find or parse the simulation data in the provided file.")
        print("   Please ensure you are using a valid results file.")
        return

    if not log_data:
        print("ü§∑ No log events found in the file.")
        return

    print(f"üî¨ Found {len(log_data)} log events to analyze.")
    output_dir.mkdir(exist_ok=True)

    # 1. Analyze the logs
    analyzer = LogAnalyzer(log_data)

    print("\n" + "="*50)
    print("üìä SUMMARY METRICS")
    print("="*50)
    summary = analyzer.get_summary_metrics()
    for key, value in summary.items():
        if isinstance(value, float):
            print(f"  - {key.replace('_', ' ').title()}: {value:.3f}")
        else:
            print(f"  - {key.replace('_', ' ').title()}: {value}")

    print("\n" + "="*50)
    print("üõ†Ô∏è TOOL PERFORMANCE")
    print("="*50)
    tool_perf = analyzer.get_tool_performance()
    print(tool_perf.to_string(index=False))

    print("\n" + "="*50)
    print("üî• FAILURE ANALYSIS")
    print("="*50)
    failures = analyzer.get_failure_analysis()
    if not failures.empty:
        print(failures.to_string(index=False))
    else:
        print("  üéâ No failures recorded.")

    print("\n" + "="*50)
    print("üîÑ STATE CHANGE ANALYSIS")
    print("="*50)
    state_analysis = analyzer.get_state_change_analysis()
    if not state_analysis.empty:
        print(state_analysis.to_string(index=False))
    else:
        print("  ü§∑ No state change data available to analyze.")

    # 2. Visualize the results
    print("\n" + "="*50)
    print("üìà GENERATING VISUALIZATIONS")
    print("="*50)
    visualizer = LogVisualizer(analyzer)

    try:
        # Summary Dashboard
        summary_fig = visualizer.create_summary_dashboard()
        summary_path = output_dir / "summary_dashboard.html"
        summary_fig.write_html(summary_path)
        print(f"  ‚úÖ Summary dashboard saved to: {summary_path}")

        # Failure Analysis Plot
        failure_fig = visualizer.create_failure_analysis_plot()
        failure_path = output_dir / "failure_analysis.html"
        failure_fig.write_html(failure_path)
        print(f"  ‚úÖ Failure analysis plot saved to: {failure_path}")

        # State Change Plot
        state_change_fig = visualizer.create_state_change_plot()
        state_change_path = output_dir / "state_change_analysis.html"
        state_change_fig.write_html(state_change_path)
        print(f"  ‚úÖ State change analysis plot saved to: {state_change_path}")

        # Bottleneck Plot
        bottleneck_fig = visualizer.create_performance_bottleneck_plot()
        bottleneck_path = output_dir / "performance_bottlenecks.html"
        bottleneck_fig.write_html(bottleneck_path)
        print(f"  ‚úÖ Performance bottleneck plot saved to: {bottleneck_path}")

    except Exception as e:
        print(f"  ‚ùå Error during visualization: {e}")

    print("\nüéâ Analysis complete!")


def main():
    parser = argparse.ArgumentParser(
        description="Analyze simplified execution logs from tau2-enhanced."
    )
    parser.add_argument(
        "log_file",
        type=Path,
        help="Path to the JSON results file containing execution_logs."
    )
    parser.add_argument(
        "-o", "--output",
        type=Path,
        default=Path("analysis_results"),
        help="Base directory to save analysis plots."
    )
    args = parser.parse_args()

    # Create a subfolder in the output directory named after the input file
    output_subdir = args.output / args.log_file.stem
    print(f"üíæ Output will be saved to: {output_subdir}")

    analyze_logs(args.log_file, output_subdir)


if __name__ == "__main__":
    main()
