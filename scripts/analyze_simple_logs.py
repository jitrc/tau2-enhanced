#!/usr/bin/env python3
"""
Analysis script for simplified execution logs from tau2-enhanced.

This script uses the new LogAnalyzer and LogVisualizer to process the
execution logs generated by the LoggingEnvironment and produces both
a console report and interactive HTML visualizations.
"""

import argparse
import json
from pathlib import Path
import sys

# Add the parent directory to the path to allow imports from tau2_enhanced
sys.path.append(str(Path(__file__).resolve().parents[1]))

from tau2_enhanced.analysis.analyzer import LogAnalyzer
from tau2_enhanced.analysis.visualizer import LogVisualizer


def analyze_logs(log_file: Path, output_dir: Path):
    """
    Loads, analyzes, and visualizes execution logs from a file.

    Args:
        log_file: Path to the JSON file containing the execution logs.
        output_dir: Directory to save the analysis reports and plots.
    """
    print(f"ğŸ“ Loading logs from: {log_file}")
    try:
        with log_file.open('r') as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âŒ Error loading log file: {e}")
        return

    # The logs are nested within a `Results` -> `Simulation` structure.
    # The `simulations` key can be a dictionary, so we'll grab the first one.
    try:
        first_simulation = next(iter(data['simulations'].values()))
        log_data = first_simulation['execution_logs']
    except (KeyError, IndexError, TypeError, StopIteration):
        print("âŒ Could not find 'simulations.{id}.execution_logs' in the provided file.")
        print("   Please ensure you are using a results file with the expected structure.")
        return

    if not log_data:
        print("ğŸ¤· No log events found in the file.")
        return

    print(f"ğŸ”¬ Found {len(log_data)} log events to analyze.")
    output_dir.mkdir(exist_ok=True)

    # 1. Analyze the logs
    analyzer = LogAnalyzer(log_data)

    print("\n" + "="*50)
    print("ğŸ“Š SUMMARY METRICS")
    print("="*50)
    summary = analyzer.get_summary_metrics()
    for key, value in summary.items():
        if isinstance(value, float):
            print(f"  - {key.replace('_', ' ').title()}: {value:.3f}")
        else:
            print(f"  - {key.replace('_', ' ').title()}: {value}")

    print("\n" + "="*50)
    print("ğŸ› ï¸ TOOL PERFORMANCE")
    print("="*50)
    tool_perf = analyzer.get_tool_performance()
    print(tool_perf.to_string(index=False))

    print("\n" + "="*50)
    print("ğŸ”¥ FAILURE ANALYSIS")
    print("="*50)
    failures = analyzer.get_failure_analysis()
    if not failures.empty:
        print(failures.to_string(index=False))
    else:
        print("  ğŸ‰ No failures recorded.")

    # 2. Visualize the results
    print("\n" + "="*50)
    print("ğŸ“ˆ GENERATING VISUALIZATIONS")
    print("="*50)
    visualizer = LogVisualizer(analyzer)

    try:
        # Summary Dashboard
        summary_fig = visualizer.create_summary_dashboard()
        summary_path = output_dir / "summary_dashboard.html"
        summary_fig.write_html(summary_path)
        print(f"  âœ… Summary dashboard saved to: {summary_path}")

        # Failure Analysis Plot
        failure_fig = visualizer.create_failure_analysis_plot()
        failure_path = output_dir / "failure_analysis.html"
        failure_fig.write_html(failure_path)
        print(f"  âœ… Failure analysis plot saved to: {failure_path}")

        # Bottleneck Plot
        bottleneck_fig = visualizer.create_performance_bottleneck_plot()
        bottleneck_path = output_dir / "performance_bottlenecks.html"
        bottleneck_fig.write_html(bottleneck_path)
        print(f"  âœ… Performance bottleneck plot saved to: {bottleneck_path}")

    except Exception as e:
        print(f"  âŒ Error during visualization: {e}")

    print("\nğŸ‰ Analysis complete!")


def main():
    parser = argparse.ArgumentParser(
        description="Analyze simplified execution logs from tau2-enhanced."
    )
    parser.add_argument(
        "log_file",
        type=Path,
        help="Path to the JSON results file containing execution_logs."
    )
    parser.add_argument(
        "-o", "--output",
        type=Path,
        default=Path("analysis_results"),
        help="Base directory to save analysis plots."
    )
    args = parser.parse_args()

    # Create a subfolder in the output directory named after the input file
    output_subdir = args.output / args.log_file.stem
    print(f"ğŸ’¾ Output will be saved to: {output_subdir}")

    analyze_logs(args.log_file, output_subdir)


if __name__ == "__main__":
    main()
